{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "breeds_sizes = [\n",
    "    (\"Labrador Retriever\", \"large\"),\n",
    "    (\"Golden Retriever\", \"large\"),\n",
    "    (\"German Shepherd\", \"large\"),\n",
    "    (\"Rottweiler\", \"large\"),\n",
    "    (\"Great Dane\", \"large\"),\n",
    "    (\"Doberman Pinscher\", \"large\"),\n",
    "    (\"Siberian Husky\", \"medium\"),\n",
    "    (\"Bulldog\", \"medium\"),\n",
    "    (\"Boxer\", \"medium\"),\n",
    "    (\"Australian Shepherd\", \"medium\"),\n",
    "    (\"Border Collie\", \"medium\"),\n",
    "    (\"Beagle\", \"small\"),\n",
    "    (\"Dachshund\", \"small\"),\n",
    "    (\"Poodle\", \"small\"),\n",
    "    (\"Chihuahua\", \"small\"),\n",
    "    (\"French Bulldog\", \"small\"),\n",
    "    (\"Yorkshire Terrier\", \"small\"),\n",
    "    (\"Shih Tzu\", \"small\"),\n",
    "    (\"Maltese\", \"small\"),\n",
    "    (\"Pomeranian\", \"small\"),\n",
    "    (\"French Griffon\", \"small\")\n",
    "]\n",
    "\n",
    "genders = [\"Male\", \"Female\"]\n",
    "\n",
    "num_rows = 2500\n",
    "\n",
    "username_list = random.sample(range(1000, 10000), num_rows)\n",
    "\n",
    "data = {\n",
    "    \"username\": [],\n",
    "    \"pet_breed\": [],\n",
    "    \"age\": [],\n",
    "    \"size\": [],\n",
    "    \"gender\": [],\n",
    "    \"latitude\": [],\n",
    "    \"longitude\": []\n",
    "}\n",
    "\n",
    "for i in range(num_rows):\n",
    "    # Pick a random breed-size pair\n",
    "    breed, size = random.choice(breeds_sizes)\n",
    "    \n",
    "    # Random age between 1 and 15\n",
    "    age = random.randint(1, 15)\n",
    "    \n",
    "    # Random gender\n",
    "    gender = random.choice(genders)\n",
    "    \n",
    "    # Random geographic coordinates in Egypt\n",
    "    lat = random.uniform(22.0, 31.0)\n",
    "    lon = random.uniform(25.0, 36.0)\n",
    "    \n",
    "    data[\"username\"].append(username_list[i])\n",
    "    data[\"pet_breed\"].append(breed)\n",
    "    data[\"age\"].append(age)\n",
    "    data[\"size\"].append(size)\n",
    "    data[\"gender\"].append(gender)\n",
    "    data[\"latitude\"].append(lat)\n",
    "    data[\"longitude\"].append(lon)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"datasetTest2500.csv\", index=False)\n",
    "\n",
    "# Show a small sample of the generated data\n",
    "print(\"A dataset with 5,000 rows (all located in Egypt) has been generated and saved to 'clean_pet_dataset_5000.csv'.\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline  # Uncomment if you'd like inline plots in Jupyter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame Head:\n",
      "   username       pet_breed  age    size  gender   latitude  longitude\n",
      "0      7831        Shih Tzu    9   small    Male  22.412832  30.484499\n",
      "1      5344  Siberian Husky    3  medium    Male  28.011713  32.182210\n",
      "2      1014  Siberian Husky    3  medium  Female  22.598486  34.320943\n",
      "3      5584          Beagle   14   small  Female  30.139795  29.570332\n",
      "4      8951  French Griffon    3   small  Female  25.102105  26.632985\n",
      "\n",
      "Initial DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   username   2500 non-null   int64  \n",
      " 1   pet_breed  2500 non-null   object \n",
      " 2   age        2500 non-null   int64  \n",
      " 3   size       2500 non-null   object \n",
      " 4   gender     2500 non-null   object \n",
      " 5   latitude   2500 non-null   float64\n",
      " 6   longitude  2500 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 136.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace 'petProfiles.csv' with your actual CSV file name/path\n",
    "df = pd.read_csv('datasetTest2500.csv')\n",
    "\n",
    "print(\"Initial DataFrame Head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInitial DataFrame Info:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Encoding & Casting, DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   username                       2500 non-null   float32\n",
      " 1   age                            2500 non-null   float32\n",
      " 2   latitude                       2500 non-null   float32\n",
      " 3   longitude                      2500 non-null   float32\n",
      " 4   pet_breed_Australian Shepherd  2500 non-null   float32\n",
      " 5   pet_breed_Beagle               2500 non-null   float32\n",
      " 6   pet_breed_Border Collie        2500 non-null   float32\n",
      " 7   pet_breed_Boxer                2500 non-null   float32\n",
      " 8   pet_breed_Bulldog              2500 non-null   float32\n",
      " 9   pet_breed_Chihuahua            2500 non-null   float32\n",
      " 10  pet_breed_Dachshund            2500 non-null   float32\n",
      " 11  pet_breed_Doberman Pinscher    2500 non-null   float32\n",
      " 12  pet_breed_French Bulldog       2500 non-null   float32\n",
      " 13  pet_breed_French Griffon       2500 non-null   float32\n",
      " 14  pet_breed_German Shepherd      2500 non-null   float32\n",
      " 15  pet_breed_Golden Retriever     2500 non-null   float32\n",
      " 16  pet_breed_Great Dane           2500 non-null   float32\n",
      " 17  pet_breed_Labrador Retriever   2500 non-null   float32\n",
      " 18  pet_breed_Maltese              2500 non-null   float32\n",
      " 19  pet_breed_Pomeranian           2500 non-null   float32\n",
      " 20  pet_breed_Poodle               2500 non-null   float32\n",
      " 21  pet_breed_Rottweiler           2500 non-null   float32\n",
      " 22  pet_breed_Shih Tzu             2500 non-null   float32\n",
      " 23  pet_breed_Siberian Husky       2500 non-null   float32\n",
      " 24  pet_breed_Yorkshire Terrier    2500 non-null   float32\n",
      " 25  size_large                     2500 non-null   float32\n",
      " 26  size_medium                    2500 non-null   float32\n",
      " 27  size_small                     2500 non-null   float32\n",
      " 28  gender_Female                  2500 non-null   float32\n",
      " 29  gender_Male                    2500 non-null   float32\n",
      "dtypes: float32(30)\n",
      "memory usage: 293.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Identify your categorical columns (if they exist)\n",
    "categorical_cols = []\n",
    "if 'pet_breed' in df.columns:\n",
    "    categorical_cols.append('pet_breed')\n",
    "if 'size' in df.columns:\n",
    "    categorical_cols.append('size')\n",
    "if 'gender' in df.columns:\n",
    "    categorical_cols.append('gender')\n",
    "\n",
    "# One-hot encode these columns to avoid string-to-float issues\n",
    "if len(categorical_cols) > 0:\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "# Fill missing numeric columns if needed (example for 'age', 'latitude', 'longitude')\n",
    "if 'age' in df.columns:\n",
    "    df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "if 'latitude' in df.columns:\n",
    "    df['latitude'].fillna(df['latitude'].mean(), inplace=True)\n",
    "if 'longitude' in df.columns:\n",
    "    df['longitude'].fillna(df['longitude'].mean(), inplace=True)\n",
    "\n",
    "# Cast everything to float32\n",
    "df = df.astype('float32')\n",
    "\n",
    "print(\"\\nAfter Encoding & Casting, DataFrame Info:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2000\n",
      "Test set size:  500\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size:  {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Compute the Haversine distance in kilometers between two points specified in degrees.\n",
    "    \"\"\"\n",
    "    R = 6371.0  # Earth radius in km\n",
    "    d_lat = math.radians(lat2 - lat1)\n",
    "    d_lon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(d_lat / 2)**2\n",
    "         + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2))\n",
    "         * math.sin(d_lon / 2)**2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(df_subset, age_threshold=4.0, distance_threshold=50.0):\n",
    "    \"\"\"\n",
    "    df_subset: DataFrame with numeric columns, including:\n",
    "       breed_..., size_..., gender_..., age, latitude, longitude\n",
    "\n",
    "    Returns: (pairs_array, labels_array)\n",
    "      pairs_array shape: [num_pairs, 2, num_features]\n",
    "      labels_array shape: [num_pairs,]\n",
    "\n",
    "    Label=1 if:\n",
    "      1) Opposite gender\n",
    "      2) Haversine distance < distance_threshold\n",
    "      3) |age1 - age2| <= age_threshold\n",
    "      4) (same breed OR same size)\n",
    "    Otherwise label=0.\n",
    "    \"\"\"\n",
    "    data = df_subset.values  # shape: (num_rows, num_features)\n",
    "    columns = list(df_subset.columns)\n",
    "\n",
    "    # Identify columns\n",
    "    breed_cols  = [c for c in columns if c.startswith('pet_breed_')]\n",
    "    size_cols   = [c for c in columns if c.startswith('size_')]\n",
    "    gender_cols = [c for c in columns if c.startswith('gender_')]\n",
    "\n",
    "    lat_idx = columns.index('latitude')\n",
    "    lon_idx = columns.index('longitude')\n",
    "    age_idx = columns.index('age')\n",
    "\n",
    "    # Convert col names to indices for breed, size, gender\n",
    "    breed_indices  = [columns.index(c) for c in breed_cols]\n",
    "    size_indices   = [columns.index(c) for c in size_cols]\n",
    "    gender_indices = [columns.index(c) for c in gender_cols]\n",
    "\n",
    "    def opposite_gender(vecA, vecB):\n",
    "        # We assume columns like 'gender_Male', 'gender_Female'\n",
    "        try:\n",
    "            idx_male   = [i for i, c in enumerate(gender_cols) if 'Male'   in c][0]\n",
    "            idx_female = [i for i, c in enumerate(gender_cols) if 'Female' in c][0]\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "        male_idx   = gender_indices[idx_male]\n",
    "        female_idx = gender_indices[idx_female]\n",
    "\n",
    "        A_is_male = (vecA[male_idx] > 0.5)\n",
    "        A_is_fem  = (vecA[female_idx] > 0.5)\n",
    "        B_is_male = (vecB[male_idx] > 0.5)\n",
    "        B_is_fem  = (vecB[female_idx] > 0.5)\n",
    "\n",
    "        return (A_is_male and B_is_fem) or (A_is_fem and B_is_male)\n",
    "\n",
    "    def within_distance(vecA, vecB, km_thresh):\n",
    "        lat1, lon1 = vecA[lat_idx], vecA[lon_idx]\n",
    "        lat2, lon2 = vecB[lat_idx], vecB[lon_idx]\n",
    "        dist_km = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "        return (dist_km <= km_thresh)\n",
    "\n",
    "    def age_in_range(vecA, vecB, max_diff):\n",
    "        return abs(vecA[age_idx] - vecB[age_idx]) <= max_diff\n",
    "\n",
    "    pairs_list = []\n",
    "    labels_list = []\n",
    "    num_rows = data.shape[0]\n",
    "\n",
    "    for i in range(num_rows - 1):\n",
    "        for j in range(i + 1, num_rows):\n",
    "            petA = data[i]\n",
    "            petB = data[j]\n",
    "            label = 0.0\n",
    "\n",
    "            # Opposite gender\n",
    "            if opposite_gender(petA, petB):\n",
    "                # Within 50 km\n",
    "                if within_distance(petA, petB, distance_threshold):\n",
    "                    # Age difference <= 4 years\n",
    "                    if age_in_range(petA, petB, age_threshold):\n",
    "                        # Same breed OR same size\n",
    "                        same_breed = False\n",
    "                        for idx_b in breed_indices:\n",
    "                            if (petA[idx_b] > 0.5) and (petB[idx_b] > 0.5):\n",
    "                                same_breed = True\n",
    "                                break\n",
    "                        same_size = False\n",
    "                        for idx_s in size_indices:\n",
    "                            if (petA[idx_s] > 0.5) and (petB[idx_s] > 0.5):\n",
    "                                same_size = True\n",
    "                                break\n",
    "\n",
    "                        if same_breed or same_size:\n",
    "                            label = 1.0\n",
    "\n",
    "            pairs_list.append([petA, petB])\n",
    "            labels_list.append(label)\n",
    "\n",
    "    pairs_array  = np.array(pairs_list,  dtype='float32')  \n",
    "    labels_array = np.array(labels_list, dtype='float32')\n",
    "    return pairs_array, labels_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: (1999000, 2, 30),  Train labels: (1999000,)\n",
      "Test pairs:  (124750, 2, 30),   Test labels:  (124750,)\n"
     ]
    }
   ],
   "source": [
    "pairs_train, labels_train = create_pairs(train_df, age_threshold=4.0, distance_threshold=50.0)\n",
    "pairs_test,  labels_test  = create_pairs(test_df,  age_threshold=4.0, distance_threshold=50.0)\n",
    "\n",
    "print(f\"Train pairs: {pairs_train.shape},  Train labels: {labels_train.shape}\")\n",
    "print(f\"Test pairs:  {pairs_test.shape},   Test labels:  {labels_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pet1_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " pet2_input (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 16)           4592        ['pet1_input[0][0]',             \n",
      "                                                                  'pet2_input[0][0]']             \n",
      "                                                                                                  \n",
      " distance (Lambda)              (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,592\n",
      "Trainable params: 4,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Separate pairs into (petA, petB) for training\n",
    "pet_features_1_train = pairs_train[:, 0]\n",
    "pet_features_2_train = pairs_train[:, 1]\n",
    "\n",
    "# And for testing\n",
    "pet_features_1_test  = pairs_test[:, 0]\n",
    "pet_features_2_test  = pairs_test[:, 1]\n",
    "\n",
    "def create_subnetwork(input_shape):\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = layers.Dense(64, activation='relu')(inp)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)  # final embedding dimension\n",
    "    return models.Model(inp, x)\n",
    "\n",
    "# Build subnetwork\n",
    "input_shape = (pet_features_1_train.shape[1],)\n",
    "pet_network = create_subnetwork(input_shape)\n",
    "\n",
    "# Siamese model\n",
    "input_pet1 = Input(shape=input_shape, name='pet1_input')\n",
    "input_pet2 = Input(shape=input_shape, name='pet2_input')\n",
    "\n",
    "embedding_pet1 = pet_network(input_pet1)\n",
    "embedding_pet2 = pet_network(input_pet2)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    petA, petB = vectors\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(petA - petB), axis=1, keepdims=True))\n",
    "\n",
    "distance = layers.Lambda(euclidean_distance, name='distance')([embedding_pet1, embedding_pet2])\n",
    "model = models.Model(inputs=[input_pet1, input_pet2], outputs=distance)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49975/49975 [==============================] - 225s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/5\n",
      "49975/49975 [==============================] - 203s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/5\n",
      "36101/49975 [====================>.........] - ETA: 56s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28200\\235670875.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mcontrastive_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmargin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     return K.mean(\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[1;31m# If eval data_handler exists, delete it after all epochs are done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_eval_data_handler\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m         ):\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4070\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4071\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4072\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4073\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4074\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4075\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4076\u001b[0m       return identity_eager_fallback(\n\u001b[0;32m   4077\u001b[0m           input, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    margin = 1.0\n",
    "    return K.mean(\n",
    "        y_true * K.square(y_pred) +\n",
    "        (1 - y_true) * K.square(tf.maximum(margin - y_pred, 0))\n",
    "    )\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=contrastive_loss)\n",
    "\n",
    "history = model.fit(\n",
    "    [pet_features_1_train, pet_features_2_train],\n",
    "    labels_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate([pet_features_1_test, pet_features_2_test], labels_test)\n",
    "print(\"\\nTest Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want to embed all the test rows:\n",
    "test_data = test_df.values  # shape: (num_test_rows, num_features)\n",
    "all_test_embeddings = pet_network.predict(test_data)\n",
    "\n",
    "# Choose a query row (e.g., index 0)\n",
    "query_idx = 0\n",
    "query_vec = test_data[query_idx].reshape(1, -1)\n",
    "query_emb = pet_network.predict(query_vec)\n",
    "\n",
    "# Compute Euclidean distances\n",
    "distances = np.linalg.norm(all_test_embeddings - query_emb, axis=1)\n",
    "distances[query_idx] = np.inf  # so it won't match itself\n",
    "\n",
    "top_k = 5\n",
    "closest_idx = np.argsort(distances)[:top_k]\n",
    "print(f\"Top {top_k} matches for test row #{query_idx}:\", closest_idx)\n",
    "print(\"Distances:\", distances[closest_idx])\n",
    "\n",
    "# If you kept an original reference DataFrame with textual data,\n",
    "# you could map these indices back to see the matched rows' info.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
